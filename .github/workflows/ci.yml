name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  contents: read

jobs:
  test:
    name: Test on Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write

    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11", "3.12", "3.13", "3.14"]

    steps:
    - name: Checkout code
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python ${{ matrix.python-version }}
      run: uv python install ${{ matrix.python-version }}

    - name: Install dependencies
      run: uv sync --all-extras

    - name: Run ruff linting
      run: uv run ruff check src/ tests/

    - name: Run ruff formatting check
      run: uv run ruff format --check src/ tests/

    - name: Run mypy type checking
      run: uv run mypy src/mcp_docker/

    - name: Run unit tests with coverage
      run: |
        uv run pytest tests/unit/ \
          -v \
          --cov=mcp_docker \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=85 \
          --junitxml=junit/test-results-${{ matrix.python-version }}.xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@5a1091511ad55cbe89839c7260b706298ca349f7 # v5.5.1
      if: matrix.python-version == '3.11'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        token: ${{ secrets.CODECOV_TOKEN }}
      continue-on-error: true

    - name: Publish test results
      uses: EnricoMi/publish-unit-test-result-action@34d7c956a59aed1bfebf31df77b8de55db9bbaaf # v2.21.0
      if: always()
      with:
        files: |
          junit/test-results-${{ matrix.python-version }}.xml
        check_name: Unit Test Results (Python ${{ matrix.python-version }})
        comment_mode: off

    - name: Upload coverage HTML report
      uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
      if: always()
      with:
        name: coverage-report-${{ matrix.python-version }}
        path: htmlcov/
        retention-days: 30

    - name: Upload test results
      uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          junit/
          coverage.xml
        retention-days: 30

    - name: Generate coverage report
      id: coverage
      if: matrix.python-version == '3.11'
      run: |
        echo "coverage=$(uv run coverage report | grep TOTAL | awk '{print $4}')" >> $GITHUB_OUTPUT
        echo "## üìä Coverage Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        uv run coverage report >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY

  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write

    services:
      docker:
        image: docker:24-dind
        options: --privileged

    steps:
    - name: Checkout code
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Set up Docker
      run: |
        # Docker is already available in ubuntu-latest
        docker --version

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python 3.11
      run: uv python install 3.11

    - name: Install dependencies
      run: uv sync --all-extras

    - name: Pull test images
      run: |
        docker pull alpine:latest
        docker pull alpine:3.18

    - name: Run integration tests
      run: |
        uv run pytest tests/integration/ \
          -v \
          -m "integration" \
          --tb=short \
          --maxfail=5 \
          --junitxml=junit/integration-results.xml \
          --no-cov

    - name: Publish integration test results
      uses: EnricoMi/publish-unit-test-result-action@34d7c956a59aed1bfebf31df77b8de55db9bbaaf # v2.21.0
      if: always()
      with:
        files: |
          junit/integration-results.xml
        check_name: Integration Test Results
        comment_mode: off

    - name: Upload integration test results
      uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
      if: always()
      with:
        name: integration-test-results
        path: junit/
        retention-days: 30

    - name: Cleanup Docker resources
      if: always()
      run: |
        docker system prune -af --volumes || true

  e2e-test:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [integration-test]  # Run after integration tests pass
    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
    - name: Checkout code
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Set up Docker
      run: |
        # Docker is already available in ubuntu-latest
        docker --version

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python 3.11
      run: uv python install 3.11

    - name: Install dependencies
      run: uv sync --all-extras

    - name: Pull test images
      run: |
        docker pull alpine:latest
        docker pull alpine:3.19

    - name: Run E2E tests (for PRs)
      if: github.event_name == 'pull_request'
      run: |
        uv run pytest tests/e2e/ \
          -v \
          -m "e2e and not stress" \
          --tb=short \
          --maxfail=3 \
          --junitxml=junit/e2e-results.xml \
          --no-cov

    - name: Run E2E tests (full - for main branch)
      if: github.ref == 'refs/heads/main'
      run: |
        uv run pytest tests/e2e/ \
          -v \
          -m "e2e and not stress" \
          --tb=short \
          --maxfail=5 \
          --junitxml=junit/e2e-results.xml \
          --no-cov

    - name: Publish E2E test results
      uses: EnricoMi/publish-unit-test-result-action@34d7c956a59aed1bfebf31df77b8de55db9bbaaf # v2.21.0
      if: always()
      with:
        files: |
          junit/e2e-results.xml
        check_name: E2E Test Results
        comment_mode: off

    - name: Upload E2E test results
      uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
      if: always()
      with:
        name: e2e-test-results
        path: junit/
        retention-days: 30

    - name: Cleanup Docker resources
      if: always()
      run: |
        docker system prune -af --volumes || true

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python 3.11
      run: uv python install 3.11

    - name: Install dependencies
      run: uv sync --all-extras

    - name: Run safety check
      run: |
        uv pip install safety
        uv run safety check --json || true
      continue-on-error: true

    - name: Run bandit security linter
      run: |
        uv pip install bandit
        uv run bandit -r src/ -f json || true
      continue-on-error: true

  build:
    name: Build Package
    runs-on: ubuntu-latest
    needs: [test]
    permissions:
      contents: read

    steps:
    - name: Checkout code
      uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python 3.11
      run: uv python install 3.11

    - name: Install dependencies
      run: uv sync

    - name: Build package
      run: uv build

    - name: Upload package artifacts
      uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
      with:
        name: dist-packages
        path: dist/
        retention-days: 7

  pr-comment:
    name: PR Test Summary
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [test, integration-test, e2e-test]
    permissions:
      pull-requests: write
      contents: read

    steps:
    - name: Download all test results
      uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
      with:
        pattern: '*-results*'
        merge-multiple: true

    - name: Download coverage reports
      uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
      with:
        name: coverage-report-3.11
        path: htmlcov/

    - name: Install uv
      uses: astral-sh/setup-uv@681c641aba71e4a1c380be3ab5e12ad51f415867 # v7.1.6
      with:
        version: "latest"

    - name: Set up Python 3.11
      run: uv python install 3.11

    - name: Create virtual environment
      run: uv venv

    - name: Install pytest for result parsing
      run: uv pip install pytest junitparser

    - name: Generate test summary
      id: summary
      run: |
        # Debug: List all downloaded files
        echo "=== Files in current directory ==="
        find . -name "*.xml" -type f
        echo "==================================="

        uv run python3 << 'EOF'
        import json
        import os
        from pathlib import Path
        from junitparser import JUnitXml

        # Parse JUnit XML files
        results = {}
        # Find XML files in both junit/ directory and root (for merged artifacts)
        xml_files = list(Path('.').glob('junit/**/*.xml')) + list(Path('.').glob('*.xml'))
        # Filter out coverage.xml which is not a test results file
        xml_files = [f for f in xml_files if 'coverage' not in f.name]
        print(f"Found {len(xml_files)} XML files: {[str(f) for f in xml_files]}")

        for xml_file in xml_files:
            # Parse suite name: integration-results -> integration, e2e-results -> e2e, test-results-3.11 -> 3.11
            suite_name = xml_file.stem.replace('-results', '').replace('test-', '')
            xml = JUnitXml.fromfile(str(xml_file))

            total = xml.tests
            failures = xml.failures
            errors = xml.errors
            skipped = xml.skipped
            passed = total - failures - errors - skipped
            time = xml.time

            results[suite_name] = {
                'total': total,
                'passed': passed,
                'failed': failures + errors,
                'skipped': skipped,
                'time': time
            }

        # Write summary
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f"results={json.dumps(results)}\n")
        EOF

    - name: Comment PR
      uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
      with:
        script: |
          const results = JSON.parse('${{ steps.summary.outputs.results }}');

          // Build results table
          let tableRows = '';
          let allPassed = true;

          for (const [suite, data] of Object.entries(results)) {
            const status = data.failed === 0 ? '‚úÖ' : '‚ùå';
            if (data.failed > 0) allPassed = false;

            // Format suite name with special handling
            let suiteName;
            if (suite === 'e2e') {
              suiteName = 'E2E';
            } else if (suite.match(/^\d+\.\d+$/)) {
              // Python version numbers (3.11, 3.12, 3.13, 3.14) -> "Unit Tests - Python X.XX"
              suiteName = `Unit Tests - Python ${suite}`;
            } else {
              // Capitalize first letter for others (integration -> Integration)
              suiteName = suite.charAt(0).toUpperCase() + suite.slice(1);
            }

            const duration = data.time < 60 ? `${data.time.toFixed(0)}s` : `${(data.time / 60).toFixed(1)}m`;

            tableRows += `| ${suiteName} | ${status} | ${data.passed} | ${data.failed} | ${data.skipped} | ${duration} |\n`;
          }

          const totalTests = Object.values(results).reduce((sum, r) => sum + r.total, 0);
          const totalPassed = Object.values(results).reduce((sum, r) => sum + r.passed, 0);
          const totalFailed = Object.values(results).reduce((sum, r) => sum + r.failed, 0);
          const totalSkipped = Object.values(results).reduce((sum, r) => sum + r.skipped, 0);

          const body = `## üß™ Test Results for \`${context.payload.pull_request.head.sha.substring(0, 7)}\`

          ### Summary
          ${allPassed ? '‚úÖ **All tests passed!**' : '‚ùå **Some tests failed**'}

          | Test Suite | Status | Passed | Failed | Skipped | Duration |
          |------------|--------|--------|--------|---------|----------|
          ${tableRows}
          | **Total** | ${allPassed ? '‚úÖ' : '‚ùå'} | **${totalPassed}** | **${totalFailed}** | **${totalSkipped}** | - |

          ### üìä Coverage

          Coverage reports are available in the [workflow artifacts](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}).

          <details>
          <summary>üì¶ Download Reports</summary>

          - [Coverage HTML Report (Python 3.11)](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          - [Coverage HTML Report (Python 3.12)](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          - [Coverage HTML Report (Python 3.13)](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          - [Coverage HTML Report (Python 3.14)](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          - [Test Results (JUnit XML)](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})

          </details>

          ---

          [üìä View Full Report](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) |
          [üìù All Checks](https://github.com/${context.repo.owner}/${context.repo.repo}/pull/${context.payload.pull_request.number}/checks)`;

          // Find existing comment
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.payload.pull_request.number,
          });

          const botComment = comments.data.find(comment =>
            comment.user.type === 'Bot' &&
            comment.body.includes('üß™ Test Results for')
          );

          if (botComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: body
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body: body
            });
          }
